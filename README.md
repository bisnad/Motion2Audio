# Motion2Audio

Motion2Audio is a research project that aims to develop AI-based tools for translating dance movements into music. These tools are designed to allow dancers to freely improvise to existing music and then use recordings of these improvisations as the basis for interactively controlling the creation of music through their body movements.

### Artistic Principle

At the core of this project lies the idea that performers in contemporary dance have developed highly refined techniques and strategies for using music as a creative resource in the generation of movement. Motion2Audio seeks to adopt these techniques as the foundation for developing digital musical instruments whose interaction and sound generation are guided solely by the dancersâ€™ idiosyncratic decisions made while improvising to music.

### Technical Principe

Motion2Audio develops machine learning models that analyze a dancer's movements and translate these movements into music through neural sound synthesis. These models are trained on recordings of dancers improvising to music. Through training, the models learn the correlations between movement and sound. Once trained, they can generate new music from movement alone.

### Repository

This repository is divided into the following sections. 

- The [MotionCapture](https://github.com/bisnad/Motion2Audio/tree/main/MotionCapture) section contains tools for converting proprietary motion capture message protocols to OSC (Open Sound Control) format and for playing back motion capture recordings.
- The [Transformer](https://github.com/bisnad/Motion2Audio/tree/main/Transformer) section contains tools for training and using Transformer models that translate motion into audio.
-  The [VAE](https://github.com/bisnad/Motion2Audio/tree/main/VAE) section contains tools for training and using Variational Autoencoders to compress and reconstruct audio.

### Partners

Currently, the project runs as a collaboration between two researchers and three professional dancers.

**Researchers**

- Daniel Bisig, Institute for Computer Music and Sound Technology, Zurich University of the Arts (https://www.zhdk.ch/en/research/icst)
- Alexander Okupnik, Artificial Intelligence and Data Science, University Liechtenstein (https://www.uni.li/en/university/organisation/liechtenstein-business-school/artificial-intelligence-and-data-science)

**Dancers**

- Diane Gemsch (https://www.dianegemsch.ch/)
- Eleni Mylona (https://www.mylonaeleni.com/)
- Tim Winkler

### Example Media

https://github.com/user-attachments/assets/904f2080-76e2-4f6d-9165-09b0d59ebc91

figure 1: video and motion capture recording of dancer Diane improvising to the audio recording of her father's voice. 

https://github.com/user-attachments/assets/905a1110-ab94-47bf-bc3a-5da762bc2398

figure 2: original motion capture and audio recording  (Mocap Take 2)

https://github.com/user-attachments/assets/a7d12dca-adda-4077-af25-12253777a45a

figure 3: original motion capture recoding and audio generated by Motion2Audio (Mocap Take 2)

https://github.com/user-attachments/assets/52d19655-44ef-481d-86ff-2b630300244d

figure 3: new motion capture recording and audio generated by Motion2Audio (Mocap Take 5)

https://github.com/user-attachments/assets/96086b98-fb68-4c3d-8178-fa61263ca92c

figure 4: new motion capture recording and audio generated by Motion2Audio (Mocap Take 6)

| https://github.com/user-attachments/assets/904f2080-76e2-4f6d-9165-09b0d59ebc91 |
| ------------------------------------------------------------ |
| figure 1: video and motion capture recording of dancer Diane improvising to the audio recording of her father's voice. |

| https://github.com/user-attachments/assets/905a1110-ab94-47bf-bc3a-5da762bc2398 | https://github.com/user-attachments/assets/a7d12dca-adda-4077-af25-12253777a45a |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| figure 2: original motion capture and audio recording  (Mocap Take 2) | figure 3: original motion capture recoding and audio generated by Motion2Audio (Mocap Take 2) |
| https://github.com/user-attachments/assets/52d19655-44ef-481d-86ff-2b630300244d | https://github.com/user-attachments/assets/96086b98-fb68-4c3d-8178-fa61263ca92c |
| figure 3: new motion capture recording and audio generated by Motion2Audio (Mocap Take 5) | figure 4: new motion capture recording and audio generated by Motion2Audio (Mocap Take 6) |







